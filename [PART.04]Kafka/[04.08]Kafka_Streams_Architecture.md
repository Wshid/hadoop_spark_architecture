## 4.8. Kafka Streams Architecture

### Kafka Streams
- `지속적인 commit log`와 `Kafka Connect/Kafka Streams/KSQL`의 조합은
  - **Event Streaming Platform**을 구성
- Kafka Connect
  - Kafka와 **다른 데이터 시스템**간에 데이터를 **스트리밍**하기 위한 도구
- 데이터 변환 논리를 적용하고, 데이터의 새로운 표현을
  - **Kafka에 다시 작성**
- 변환되거나 강화된 이벤트를 `downstream`에서 사용할 수 있도록 함
- Kafka Streams는
  - 많은 소스의 데이터가 **수렴**되는 중요한 역할
- 정교한 데이터 강화, 변환, 처리가 발생할 수 있는 계층

### 주요 기능
- **Event at a time streaming**
  - 일괄 처리가 구체화될 때까지 기다리지 않음
  - 각 이벤트가 들어오는 **즉시** 처리
  - c.f. **Micro batching**
    - 레코드를 **작은 배치**로 그룹화
    - 고정된 간격으로 downstream processor로 내보내는 작업 포함
  - 주로 대기 시간이 길어지는 대신, **처리량을 높이도록** 최적화 되는 경우가 많음
- Kafka Streams에서는
  - 데이터를 **여러 파티션**으로 분할하여
  - **높은 처리량**을 유지하면서
  - 짧은 `latency`를 달성
- **윈도우 및 주기적 기능** 지원
  - tumbling window
  - hopping window
  - session window
    - 주어진 키에 대한 timeout을 설정
    - 만료될 경우, 새로운 데이터는 **새로운 세션**으로 처리
- 데이터 모델링을 위한 **SQL 추상화 계층**
- `stream`과 `table`을 `join`할 수 있음
- `stateful/stateless` 처리 가능