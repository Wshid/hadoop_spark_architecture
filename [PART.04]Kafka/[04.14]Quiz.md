## 4.14. Quiz

### Kafka의 주요 구성 요소
- Topic
  - index가 있는 대기열, 메세지가 정렬됨
- Consumer
  - Topic에서 데이터를 읽음
- Producer
  - Topic에 데이터를 작성
- Kafka는 로그에 기록을 보관
  - 로그의 위치를 추적하는 것은 `Consumer`에게 달려 있음
  - => `Offset`
- 메세지를 읽을때 `Consumer`는 `Offset`을 증가 시킴
- `Producer`는 하나 이상의 `kafka topic`에 M을 작성하고 게시
- `Partitioning`을 통해 `Producer`는
  - Broker간에 데이터를 `직렬화/압축 및 로드 밸런싱` 가능
- `Consumer`는 구독한 `topic`에서 M을 읽음
- `Consumer group`
  - group내 각 consumer는 구독한 **특정 키의 파티션**을 읽음
- `Kafka Broker`는 `kafka`의 일부로 작동하는 서버
  - 여러 `broker`가 **로드 밸런싱/안정적인 중복성 및 장애 초지**를 제공하는 `kafka cluster`에 속함
- 클러스터는 `Apache zookeeper`를 사용하여 `broker`가 관리하고 조정
- 성능 저하 없이 각 `broker instance`는
  - 초당 수십만(and Gib Messages)의 `read/write` volume 처리 가능
- 각 `broker`는 고유한 `id`를 가지며
  - 하나 이상의 **토픽 로그 분할**을 담당할 수 있음
- `Zookeeper`는
  - **리더 선택**을 위해 `kafka broker`에 의해 사용
  - topic의 **특정 파티션**에 대한 **클라이언트 요청 처리**를 주도하도록 선택됨
- 모든 `broker`에 연결하면
  - 클라이언트가 전체 `kafka cluster`의 속도를 높일 수 있음
- 안정적인 **장애 조치**를 달성하려면
  - 최소 3개의 `broker`를 사용해야 함
- `broker` 수가 많을 수록 **장애 조치의 안정성 증가**

### Kafka가 사용하는 4가지 핵심 API
- `Producer API`: App에서 하나 이상의 `kafka topic`에 데이터 게시 가능
- `Consumer API`: 하나 이상의 `kafka topic` 구독 가능
- `Streams API`: stream 처리를 사용하여 `kafka`의 데이터 처리 가능
  - 하나 이상의 `topic`에서 **입력 스트림**을 가져옴
  - `stream`작업을 사용하여 처리
  - 하나 이상의 `topic`에 전송할 **출력 스트림**을 생성
  - 입력 스트림을 **출력 스트림**으로 변환
- `Connect API`
  - `Kafka topic`을 `Application`에 연결
  - `database` 변경사항을 캡쳐하고
    - `kafka topic`에서 사용할 수 있도록 함
- `KSQL API`
  - `KSQL` 서버의 `REST endpoint`를 노출하는 API

### Kafka에서 Partition 이란
- **정렬된 메세지**를 포함하는 `partition`으로 분리
- 파티션에 고유한 `offset` 할당
- 단일 `topic`에서 **여러 파티션 로그**를 찾을 수 있음
- 여러 사용자가 **같은 topic**에서 동시에 읽을 수 있음
- `topic`을 병렬 처리할 수 있음
- 복제는 **파티션 수준**에서 수행
- `replica`는 파티션의 복사본
- 각 파티션에는 `cluster`의 여러 `broker`에서 복제되는 M이 포함된 **하나 이상의 복제본** 존재
- 하나의 `broker`가 `leader`, 나머지는 `follower`
  - `leader`: 모든 `read/write` 수행
  - `follower`: 리더 **복제**
- `lead`서버가 다운되면 `follower`중 한 명이 **리더 역할을 인계**

### Consumer Group
- `Topic`에서 데이터를 수집하기 위해
  - 함께 작업하는 여러 `Consumer`로 구성

### Kafka에서의 High Availability
- 토픽 **복제** 유지
- 하나의 `broker`가 실패하면 데이터가 손실되지 않도록
  - 다른 `broker`의 `topic 복제본` `2x, 3x`배수로 클러스터의 `topic` 수를 지정
- `replication factor`
- 각 파티션에는 `leader` 존재
- 다른 `broker`는 사용할 수 있는 **복제본**을 저장
- 복제 계수는 클러스터의 모든 `broker` 수보다 작거나 같음
- `Insync Replica`는 **리더 파티션**과 동기화되는 복제본

### Kafka Broker가 처리할 수 있는 최대 메세지 크기
- 기본 최대 메세지 크기 = `1M`
- broker 구성 설정에서 변경 가능

### Kafka는 어떤 문제에 직면할 수 있는가
- 스키마 변경 후 **대용량 메세지 압축** 및 **압축 해제**시
  - **성능 저하**를 겪을 수 있음

### Kafka의 일반적인 사용 사례
- 로그 집계, 이벤트 소싱, 스트림 처리, 웹 클릭 스트림, DB 커밋 로그, Pub/sub Messaging

### Kafka Schema Resgistry의 역할
- 스키마 `Producer`가 `Consumer`의 스키마와 일치하는지 확인

### Kafka Offset
- `partition`이 `topic`에 작성된 후
  - 레코드의 **파티션 식별**을 위해 **고유 인덱서**가 제공된 것

### RabbitMQ와 Kafka의 차이점
#### RabbitMQ
- 범용 Message Broker
- 요청/응답을 **end-to-end**에서 함
- pub/sub 통신 패턴 등에 쓰임
- **smart broker/dummy consumer model**
- `broker`가 `consumer`의 상태를 **모니터링**하는 것과 거의 같은 속도로
  - `consumer`에게 **일관된 M 전송**이 있음
- 성숙한 플랫폼
  - `Java, Client library, .Net, Ruby, Node.js`에 대해 지원
- 다양한 플러그인 지원
- 통신은 **동기식/비동기식**일 수 있음
- **분산 배포**를 위한 옵션 제공

### Confluent Kafka
- kafka framework를 `platform`으로 관리
- kafka 기본 기능 + `KSQL` + Dashboard