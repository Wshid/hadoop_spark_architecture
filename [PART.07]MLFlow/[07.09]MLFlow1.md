## 7.9. MLFlow 1
- 매개변수, 메트릭, 아티팩트, 메타데이터 및 모델
- `downstream production`에 **머신러닝 모델**을 배포하려면
  - **동기적**으로 공존해야 함
- 이러한 유형의 문제를 해결하기 위해
  - open source project인 MLFlow는
  - **재현 가능한 프로젝트**를 **패키징**하는 간단한 **추상화 계층**을 도입
- 추상화 계층
  - 결과 추적
  - `github CLI` & `jupyter notebook`과 같은 기존 도구와 함께 사용할 수 있는 **모델**을 **캡슐화**
  - 모델을 공유하기 위한 **중앙 저장소**를 통해 `MLOps`의 수명 주기 가속화

### MLFlow의 특징
- **모듈식 프레임워크 아키텍처**
- 수백, 수천 명의 developer, data scientist가 협업할 수 있는
  - `Enterprise` 규모를 위한 준비
- 많은 라이브러리를 지원
  - 사용자 정의 `Python` 코드가 있는 `python` 함수
  - 오늘날 data scientist가 사용하는 인기 있는 라이브러리들
    - `H2O, Scikit-learn, Spark MLlib, Keras, Mleap, PyTorch, Tensorflow, ONNX, XGBoost, LightGBM, Fastai`
  - 이 상호 운용성은 **모든 모델**을 어디에서나 구축/배포할 수 있는
    - 다양한 환경에서 생산할 수 있도록 하기 때문에, 매우 강력
  - e.g. 인기 있는 `ML library`로 모델을 생성할 때
    - 모델을 `docker based REST API server container`에 배포 가능
  - e.g. Azure ML, AWS Segemaker와 같은 **클라우드 플랫폼**
  - e.g. 일괄/스트리밍 인퍼런스를 위한 `Spark` 정의 함수
- 실험을 추적, 모니터링 할 수 있는 **실험/모델 UI** 제공
  - 실행, 메트릭, 로그 및 모델에 연결된 **아티팩트**에 액세스
- 모델은 `cloud` 또는 `on-promise`에 배포 가능
- `API` 기능을 사용하여 **실행, 메트릭, 모델**을 기록할 수 있음
- `python`에서 `model.predict`를 사용하고
  - 다른 `python` 기반 환경에 배포하는
  - `lambda` 함수와 같은 **추상 API 호출**로 **모델 예측 캡슐화** 가능
- `Spark, Azure, AWS, Google Cloud, Docker, Kubernetes` 등 다양한 **배포 대상**을 가짐
- 몇 줄의 코드만 작성하여 다른 곳에 모델 배포 가능
  - e.g. 각 모델 실행은 `REST API Endpoint`로 패키지 가능
    - `on-promise`의 `keras/spark ML`에서 이 작업 수행
    - 하지만 오늘날, `MLFlow`에서 모델 관리가 매우 쉬움
- `MLFlow`는 완전히 제품화된 솔루션 X