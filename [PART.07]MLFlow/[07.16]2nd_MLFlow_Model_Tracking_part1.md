## 7.16. 2nd MLFlow Run Tracking part1
- PyTorch로 된 노트북
  - `2. MLFlow Model Tracking`
  - https://github.com/maximuslee1226/mlflow/blob/master/notebooks/2.%20MLFlow%20Model%20Tracking.ipynb
- 고대 일본어 문자 인식
- 데이터 세트는 kaggle에서 가져옴
- 고대 일본 문자 -> 현대 문자로 변환하는 모델
- 분류 작업에 **DL**을 사용

#### Hyper Parameter
- 수정할 매개변수
- 배치 크기, 테스트 배치 크기, epoch 수, 참고, 학습률 등
- notebook `cpu`용 `PyTorch` 작업 초기화

#### Convolutional Neural Network
- laptop에서 실행하기 때문에
  - 두 개의 `populational layers`와
  - `fully connected layer`만 있는 `CNN`(`Convolutional neural network`를 만듦
- `Data and Dataloader Preparation`
  - 데이터 로드
  - 이후 각 이미지를 `pytorch` tensor로 변환

#### Data and Dataloader Preparation
- neural network에 데이터 공급 전 수행
- data set에서 직접 `neural network`로 이미지를 올리는 **데이터 로더**가 존재
- 중요한 매개변수 - `batch_size`, `shuffling amonunt`

#### Model and Optimizer
- 만약 많은 컴퓨팅 파워를 가진 강력한 머신이 있다면
  - `배치 크기, 에포크, 하이퍼 매개변수`를 변경하고
  - 더 많은 `optimizer`를 추가할 수 있음
- 여기서는 하나의 `optimizer`만 사용
  - `learning rate`와 `event`를 포함하는 두가지 매개변수
    - 확률적 경사하강법인 `SGD`를 사용
- laptop에 `CUDA GPU`가 있다면 성능이 더 좋음

#### Training and Testing Functions
- **이미지 분류 작업**을 위한 **훈련 테스트 함수**
- 우리는 이 함수의 **데이터셋**을 반복하고
  - **모델 출력**을 얻기 위해 **기울기**를 계산
  - `CPU`에 이미지를 넣음
- 마지막으로 **이미지 분류**를 위한 **정방향/역전파**를 수행
  - **훈련 손실**을 계산한 다음
  - **테스트 정확도**에 대한 **테스트 손실** 계산