## 5.3. Glossary

### RDD
- 분산 시스템의 **백본 요소**인
  - 클러스터 간에 **분할된 변경할 수 없는 데이터 블록**
- 여러 노드에서 **병렬**로 작동되며
  - **스파크 변환 작업** 수행
- transformation
  - lazy operation(evaluation)
  - action이 호출될 때까지 **데이터 일시적으로 보유**
  - `map, groupby, reduceby, sortbykey, filter, join, union, ...`
- action
  - 클러스터에서 실행할 job을 시작하는
    - spark driver program으로 다시 돌아가는 결과로 action을 참조
  - `reduce, collect, take, first, saveAsTextfile, saveAsSequenceFile, foreach, ...`

### SparkContext
- cluster를 spark 하기 위한 **진입점**
- RDD 및 기타 **필수 스파크 변수**를 생성하는데 사용
- **broadcast variable**
  - 작업과 함께 **복사본**을 배송하는 대신
  - 각 노드에 **캐시**된 **읽기 전용 복사본**을 유지
- **accumulator**
  - 스파크 엔진을 **이벤트 수**를 계산하는 카운터
  - 오프라인 디버거 역할

### DataFrames
- 스파크에서 가장 많이 사용되는 **데이터 구조**
- **행**과 **열**이 있는 **데이터 테이블**
  - SQL 사용자가 많이 사용

### Dataset
- RDD와 DF의 이점을 결합한 **데이터 구조**
  - RDD: 비정형 데이터
  - DF: 정형 데이터

### Apache Livy
- SparkContext 관리
- Spark 작업 제출을 위한 `REST Service`

### Jupyter Notebook
- Data scientists의 인기 있는 IDE
- 확장 가능한 인프라를 통해
  - **백엔드**에 **스파크 클러스터**
- `Livy Rest API`를 사용하여 **원격 스파크 클러스터**와 통신

### RPC
- 2개 이상의 **원격 노드**간의 통신에 사용
- `driver-executor` 및 `master-slave` 동기화를 위해 `spark`에서 사용
- block 관리, `heartbeat` 및 `streaming` 집계에 관한 것