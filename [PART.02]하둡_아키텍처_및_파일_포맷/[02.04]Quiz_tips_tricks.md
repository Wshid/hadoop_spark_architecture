## 2.4. Quiz Tips & Tricks

### SCP 및 HDFS Command를 거치지 않고 대용량 파일을 가져오는 방법
- Ambari UI 사용

### 멈출 수 없는 지속적인 Spark Job 종료 방법
- Hadoop UI에서 Spark Job을 종료 시킬 수 없을 때
- `YARN log`를 보고 정지된 특정 Spark Job에 어떤 일이 있는지 알아낼 수 있는지
  - `yarn application -list`
  - `yarn logs -applicationId [] -log_files []`
- 문제가 **리소스 제약**과 관련이 있다 판단되면
  - Hadoop에서 작업 중단 불가
- `yarn application -kill AppID`로 작업 중단 가능

### MapReduce
- 여러 서비스의 **대규모 데이터 세트**에 대해
  - **분산/병렬 처리**를 수행할 수 있는 프로그래밍 프레임워크
- `Map`은 `key, value`쌍을 출력으로 생성
- `Mapper`의 출력이 `Reducer`의 입력이 됨
- `Reducer`는 이 출력을 최종 출력으로 `aggregation`

### 두 클라이언트가 HDFS의 동일한 파일에 엑세스 하려고 하면 어떻게 되는가
- HDFS는 쓰기 전용만 지원
- 파일은 **파일을 연 첫 번째 클라이언트**에게 `lease`를 부여하는
  - `NameNode`에 의해 잠김

### HDFS에서 Block을 어떻게 정의하는가
- `block`은 `HDFS`의 가장 작은 위치
- HDFS 파일은 block 크기의 chunk로 나뉨
- Hadoop 1 - 64MB, Haddop 2 - 128MB
- 블록 크기는 수정 가능

### NameNode가 다운되면 어떻게 하겠는가
- fs metadata 복제본을 사용하여 **새로운 Namenode 시작 가능**
- 새 `Namenode`를 승인할 수 있도록 **데이터 노드 구성 필요**
- 새 `Namenode`는
  - 마지막 체크포인트 `FsImage`(메타 데이터 정보용) 로드를 완료하고
  - `Datanode`에서 **충분한 블록 보고서**를 수신한 후
  - Client service를 시작

### jps command는 무엇을 하는가
- Hadoop 데몬이 실행중인지 여부를 확인
- `Namenode, Datanode, Resource Manager, Node manager`등과 같이
  - 머신에서 실행중인 모든 `hadoop` 대몬을 보여줌

### Mapper에서 Aggregation(추가)를 수행할 수 없는 이유, 왜 Reducer가 필요한가
- `Mapper`에는 `Sorting`이 발생하지 않기 때문에
  - `Mapper`에서 `Aggreation`(addition) 수행 X
- `Sorting`은 `Reducer` 측에서만 발생하며
  - 정렬 없이 `Aggregation` 수행 X
- `Aggregation`중에 `Mapper`가 데이터 블록이 저장된 다른 시스템에서 실행중일 수 있으므로
  - `Map` 단계에서 수집할 수 없는 모든 `Mapper` 기능 출력 필요
- `Mapper`에서 데이터를 `Aggregation`하려고 하면
  - 다른 시스템에서 실행될 수 있는 모든 `Mapper` 기능간의 통신 필요
- 따라서 높은 **네트워크 대역폭**을 소비하고 **네트워크 병목 현상**을 발생시킬 수 있음

### MapReduce Framework에서 Distributed Cache란
- Application에 **필요한 파일을 캐시**하기 위해 제공하는 기능
- 작업을 위해 **파일을 캐시**하면
  - Hadoop Framework는 `map/reduce`작업이 실행중인 모든 `Datanode`에서
  - 해당 파일을 사용할 수 있도록 함
- 이후 `mapper/reducer` 작업에서
  - 캐시 파일에 **로컬 파일**로 액세스 가능

### Reducer는 어떻게 서로 통신하는가
- 서로 의사소통 하지 X
- `isolation`상태에서 `run`

### MapReduce Partitioner는 무엇을 하는가
- 단일 `key`의 모든 `value`가 동일한 `Reducer`로 이동하도록 함
- 따라서 `Reducer`를 통해 **맵 출력**을 균일하게 배포 가능
- 특정 key를 담당하는 `Reducer`를 결정하여
  - `Mapper` 출력을 `Reducer`로 redirection

### SequenceFileInputFormat이란
- 하나의 `MR`작업의 출력 사이에서
  - 다른 `MR`작업의 입력으로 데이터를 전달하는 데
  - 최적화된 특정 **압축 바이너리 파일 형식**
- `Sequence`파일은 다른 `MR`작업의 **출력**으로 생성될 수 있으며
  - 한 `MR` 작업에서 `다른 작업으로 전달되는 데이터`에 대한 **효율적인 중간 표현**
