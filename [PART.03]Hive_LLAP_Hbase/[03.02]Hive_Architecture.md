## 3.2. Hive Architecture

### Hive Internals
#### Hive CLI | Beeline
- `HiveQL` Input command를 `accept/parse`
- adhoc 쿼리를 수행하는 일반적인 방법
- Hive CLI
  - `Metastore`에 대한 연결을 포함하여
  - `Hive Client`또는 `Driver Application`이 배포될 때 사용
- Beeline
  - 경량 CLI
  - `HiveServer2`라는 여러 `Client`를 위한
    - **대규모 다중 세션 드라이버** Application에 사용
  - 시각화 도구 지원
  - **JDBC Interface** 지원(외부 Client에서 사용 가능)

#### Hive Driver Application
- `HiveQL parsing`
- 쿼리 실행 계획
- 쿼리 작업 Hadoop 제출
- 쿼리 실행 진행 모니터링

#### Hive Object
- Hive는 `HDFS`의 `Hive Obejct`에 대한 `Table` 형식 추상화를 구현
- `디렉터리/파일`을 자체 모델의 `table`로 표시
- `RDB`와 마찬가지로
  - `Table`에는 `SQL DDL`을 사용하여 생성된
  - **지정된 데이터 유형**으로 미리 정의된 **열**이 존재
- `HDFS`의 데이터는
  - 다른 DBMS와 마찬가지로, `DML`문을 통해 접근 가능
- RDBMS vs Hive?
  - HDFS는 **변경할 수 없는 파일 시스템**
  - `append`만 가능하여 `update`가 실제로 지원되지 X
- `Hive Object`는 `database`와 `table`로 구성
- `Hive database`는 `조직`, `권한 부여`, `네임스페이스 관리`에 사용
- `Hive Table`는 `Hive Database`내에 존재

#### Hive Metastore
- Hive 메타데이터의 **중앙 저장소**
- 기본 db는 **내장 Derby Database**이지만
  - `Mysql|PostgreSQL`과 같은 `local/remote db`로 지정 가능
- 대부분의 경우
  - **개발자**와 다른 사람들이
  - `Object` 정의를 **공유**할 수 있도록 하는 **공유 데이터베이스**

#### Input/Output formats & SerDes
- Hive는 `InputFormat, Serdes`를 사용하여
  - `Input`파일을 읽고
  - 처리를 위해 레코드를 추출하는 방법 결정
- `Input data Serdes`에는 다양한 유형의 `Serdes`가 존재

### Hive Client 및 서비스

#### Hive Server
- map reduce | spark 실행 엔진으로 사용하는 `hive SQL 엔진` 존재
- `Hive`는 실행 계획을 생성한 다음
  - 다음 실행 엔진을 호출하여
  - `Hive`에서 수행한 최적화로 쿼리 실행
- Hive Service를 통해
  - C는 Hive에 대해 **쿼리 실행**뿐만 아니라
  - Hive와 통신하기 위해 Hive Server에서 실행해야 하는
    - `Thrift, JDBC & ODBC Driver`를 사용하는 프로그램과 상호 작용

#### Thrift Client
- Thrift Interface는 다리 역할을 하여
  - **다른 언어**가 `Hive`에 접근할 수 있도록 함
    - 플랫폼 간 서비스를 구축하기 위한 **RPC Framework** 등
- Java Client와 상호작용하는 Thrift Server 존재
- `Spark Thrift Server`는 `Hive Server`를 대체할 수 있으며
  - `Spark`를 사용하여 **쿼리**를 실행하고 **자체 실행 계획**을 수행
  - rdd, text file과 같은 **다른 스파크 소스**에 대한 액세스 제공

#### JDBC Client
- JDBC 연결을 지원하는 모든 어플리케이션에서
  - `Live Hive Data`에 직접 연결 가능
- Beeline CLI와 같은 것

#### ODBC Client
- App이 data access를 위해 `SQL`을 사용하여 DBMS의 데이터에 접근할 수 있도록 하는
  - ODBC(Open Database Connectivity) Interface 사용
- JDBC보다 `훨씬 빠르게 로드`되지만
  - `JDBC`의 access 속도보다 느림
  - JDBC를 상대적으로 많이 사용

### Partitioning & Bucketing
- 쿼리 성능을 향상시키는 **Hive 쿼리 최적화** 기술
- `Table`에 더 많은 구조를 제공하고 **더 나은 샘플링**을 만듦

#### Partitioning
- 특정 조건을 충족하는 하위 디렉터리
- 일반적으로 `Table`의 `WHERE`절에서 사용되는 하나 이상의 조건을 기반으로 함
  - 데이터를 하위 디렉터리로 분기
- 쿼리가 속한 **파티션**만 스캔하면 되기 때문에 조회 속도가 빠름

#### Bucketing
- `ID`와 같이 **대부분 고유한 값이 있는 경우**에 사용
- 파티션 또는 `Table`에서 **각 버킷에 대한 별도의 데이터 파일**을 생성
- 각 버킷에 **전체 데이터 세트**의 알려진 **임의 비율**이 포함되므로
  - **무작위 샘플링**에 유용