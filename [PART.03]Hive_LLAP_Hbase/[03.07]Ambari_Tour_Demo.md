## 3.7. Ambari Tour Demo
- HDFS
  - 디렉터리 크기
  - CONFIG에서 관련 서렁 가능
  - 큰 덩어리의 파일을 Spark 작업 로드 시
    - Namenode, java 확인 필요
- Yarn
  - RM, NM 확인 가능
  - 특정 서비스의 실행 여부 확인 가능
  - Configuration도 다운로드 받을 수 있음
  - CONFIGS 설정 가능
    - 기본 노드에 할당하려는 리소스양
    - 컨테이너 설정
- MapReduce2
  - Config
    - Map Memory, Reduce Memory, Allocated memory, App memory
    - MR을 실행할때 필요한 것들
- Hive
  - Hive Server 2개는 대화형
  - 격리된 2개를 학습하며 기본적으로 구성
  - 리소스 이슈로 무언가가 잘못되었는지 확인 필요
  - Hive 2 AP 대화형 쿼리 활성화 시
    - 실제 대화형 쿼리, 쿼리에 대해 **MLA** 활성화 필요
  - 고급 하이브 기능 설정 가능(CONFIGS)
  - Optimization
    - 쿼리 성능 관련하여 튜닝 테스트 가능
  - Advanced
    - 데이터베이스 구성, 하이퍼니스, 일반 구성 설정
- Zookeeper
  - 모든 configuration은 Kafka, Spark에 대해 동일
  - 3개의 클러스터 노드의 quorum
  - 많은 Configuration 존재
  - CLI이동 없이 모든 Configuration parameter를 Ambari 상에서 입력 가능
- 서비스 다운시 원인 확인
  - 리소스 부족시 리소스 제공 등
  - **File View**: 기본적으로 HDFS에 대한 유효성 확인 가능
- 개별 서비스 시작 외에 **동시에 모든 서비스 중단/시작이 가능**
- Yarn Queue Manager는 기본적으로 잘 활용하지 않음
  - 스케일 배포 정도만 주로 사용
  - Scheduler의 configuration 변경
  - 설정의 이전 상태로 복구 가능
  - Configuration을 다운로드 할 수 있으나
    - 실제로 많이 활용하지 않음
- 대부분의 관리자에게 필요한 내용
  - 리소스 사용량
  - Namenode Heap
  - Disk 사용량
  - cpu, mem, network, cluster 부하
    - 어느정도 **평균과 비슷한지 확인 필요**
- Azure
  - 스스로 작동하는 `auto scale functionality`를 사용할 수 있음