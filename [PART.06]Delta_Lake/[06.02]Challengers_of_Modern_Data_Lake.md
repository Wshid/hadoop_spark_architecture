## 6.2. Challenges of Modern Deta Lake

### Bigdata Lake의 과제
- 작은 파일 관련 문제
- 느린 처리 속도
- 대기시간
- 스트리밍 및 일괄 데이터 세트 결합
- 많은 사용자 지정 코드
- 보안

### 쿼리 성능
- 쿼리 실행이 준비되기 전에 들어오는 데이터가 준비되기 까지
  - 오랜 시간이 걸릴 수 있음
- `ETL Process`가 엄청난 대기 시간을 추가할 수 있음
- 이는 사용자가 **최신 데이터에 액세스 할 수 없음**을 의미
- `Data Lake`가 성장하고, 규모가 증가하며
  - `긴 쿼리 실행 시간`은 `C`에게 허용되지 않을 수 있음
- 이는 `HDFS` 및 `Blob Storage`와 같은 **기본 추가 전용 파일 시스템**의 **작은 파일 문제**로 인해 발생

### 데이터 신뢰성
- 복잡한 데이터 파이프라인은
  - `오류`가 발생하기 쉽고
  - 리소스를 소비하기 어려움
- 들어오는 데이터의 **불완전성**과 **오류**는 매우 일반적이며
  - **downstream app**에서 오류를 일으킬 수 있음

### 시스템 복잡성
- **Data Engineer**는 일반적으로
  - **다중 홉 아키텍처**를 사용하여 파이프라인을 구성
- 파이프라인은 다양한 **비즈니스** 단위의
  - 많은 데이터소스에서 가져온 레코드의 `firehose`로 시작
- 이후 데이터는 **차원 정보**로 **정규화**되고 **풍부해짐**
- 이후 특정 **비즈니스 목표**를 위해 **필터링** 및 **집계**될 수 있음
- 마지막으로 **주요 비즈니스 메트릭**에 대한 **높은 수준의 요약**이 생성됨
- 작업동안 **스티리밍**과 **배치 분석**을 결합하는
  - **유연한 데이터 엔지니어링 파이프라인**을 구축하기 어려울 수 있음
- 이런 시스템을 구축하려면 **세련된 워크플로 엔진** 없이
  - 복잡하고 낮은 수준의 **코드**가 필요함
- **일괄 수정**을 사용하여 `스트림 처리`
- `동일한 소스/동일한 대상`에서 여러 **스트림 프로그래밍**에도 개입이 **제한됨**

### Feature Gaps
- Delta lake가 없는 최신 데이터 레이크에서 볼 수 있는 기능 격차 소개
- **Schema Changes**
  - 강화, 조인, 단계 간 변환이 중단될 수 있음
- **Pipeline Failures**
  - Failure로 인해 스테이지 간 데이터가 `drop`되거나 **복제**될 수 있음
- **Partitioning**
  - 다차원 데이터에 대해 **분할**만으로는 확장 불가
- **Tables**
  - 표준 테이블은 **최고의 지연 시간**을 위해
    - **스트리밍**과 **일괄 처리**를 결합하는 것을 허용하지 않음
- **Concurrent access**
  - 일관성 없는 쿼리 결과로 인한 **동시 액세스 문제**
- **Failing streaming jobs**
  - 스트리밍 작업 실패시,
  - 데이터 처리를 재설정하고 **다시 시작**해야할 수 있음