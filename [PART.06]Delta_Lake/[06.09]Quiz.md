## 6.9. Quiz

### 최신 Data Lake의 주요 과제
- Query Performance
  - **작은 파일 문제**로 인해, 시스템 및 쿼리 성능의 저하
- Data Reliability
  - 데이터에 오류가 발생하기 쉽다면
  - **복잡한 파이프라인**이 포함된 경우
    - 데이터 안정성 저하
- System complexity
  - **스트리밍**과 **배치 분석**을 결합한
  - **데이터 엔지니어링 파이프라인**을 구축하기 어렵게 만들 수 있음

### 최신 Data Lake의 주요 6가지 기능 격차
- **스키마 변경**은 단계간의 **조인/변환**을 엉망으로 만들 수 있음
- **파이프라인 오류**로 인해
  - 데이터가 손상되거나 복제될 수 있음
- **다차원 데이터**에 대해 **분할**만으로는 **확장 불가**
- **지연 시간 향상**을 위해
  - **테이블**에서 **스트리밍/배치**데이터의 결합을 허용하지 않음
- 일관성 없는 쿼리 결과로 인한 **동시 액세스 문제**
- 실패한 **스트리밍 작업**은 **파이프라인**을 다시 시작해야 함

### 쿼리 성능의 주요 문제
- **ETL Process**가 엄청난 **대기 시간**을 추가할 수 있고
- 들어오는 데이터가 **쿼리 실행**을 준비하기 까지
  - 오랜 시간이 걸릴 수 있음
- 최신 데이터에 액세스 할 수 없는 **사용자**
- `Data Lake`가 급격히 증가하고
  - 긴 쿼리 시간은 C는 받아들이기 어려움
- 문제의 근본 원인
  - `HDFS/Blob Storage`와 같은 기본 **추가 전용 파일 시스템**의 **작은 파일 문제**로 인해 발생

### Delta Lake의 주요 기능
#### ACID Transaction
- Data Lake에는 일반적으로 **동시에 read/write**하는 여러 파이프라인이 존재
- `Transaction`이 없기 때문에
  - Data Engineer는 **데이터 무결성**을 보장하기 위해
  - 일련의 프로세스를 거쳐야 함
- `Delta Lake`는 `Data Lake + ACID Transaction`을 가져옴
- **직렬화 가능성**, **강력한 격리 수준**

#### 확장 가능한 메타 데이터 처리
  - 빅데이터에서는 **metadata** 자체도 빅데이터가 될 수 있음
  - `Delta Lake`는 모든 `metadata`를 처리하기 위해
    - Spark의 **분산 처리 능력**을 활용하여
    - metadata를 **데이터**처럼 취급
  - `Delta Lake`는 `nB`개의 `PB`규모 테이블 처리 가능
  - `Delta Table`처럼 `Partition/File`을 간편하게 함
  - 신뢰성이 높고 효과적

#### 통합 배치 및 스트리밍 소스 및 싱크
  - `Delta Lake`의 테이블은 아래 내용이 모두 기본적으로 작동
    - **배치 테이블**이자
    - `Streaming source/sink`
    - 데이터 수집/배치 기록
    - `Backfill`및 `interactive query`
#### 스키마 시행
- 스키마를 지정하고 적용하는 기능 제공
- 데이터 유형이 정확하고
- **필수 열**이 있는지 확인하는데 도움이 돔
- 잘못된 데이터로 인해 **데이터 손상**이 발생하지 않도록 방지

#### 스키마 진화
  - 지속적으로 변화하는 `Delta Lake`를 사용하면
  - 번거로운 `DDL`없이 자동으로 적용할 수 있는 `Schema Evolution`이 가능
#### Time Travel(Data Version)
- `감사, 롤백, 실험 재현`을 위해
- **이전 버전의 데이터**에 접근하고 되돌릴 수 있도록
  - **데이터 스냅샷**을 제공

#### Update/Delete
  - `dataset`을 `merge/update/delete`하기 위한 `Scala/Java` API를 지원
  - 이를 통해 `GDPR/CCPA`를 쉽게 준수할 수 있으며
  - **변경 데이터 캡처**와 같은 **사용 사례 간소화**도 가능

#### 감사 기록
  - `transaction log`는 **변경 사항**에 대한 **전체 감사 추적**을 제공하는
  - 데이터의 **모든 변경 사항**에 대한 **세부 정보**를 기록
#### `Apache Spark API`와 100% 호환
  - 최소한의 변경으로 **기존 데이터 파이프라인**과 함께 `Delta Lake`를 사용할 수 있음

### Delta Lake는 Data Stroage System을 어떻게 최적화 하는가
- **버전**이 지정된 `Parquet` 파일을 사용하여
  - Cloud Storage에 데이터를 저장
- `ACID Transaction`을 제공하기 위해
  - `Table/Blob storage` 디렉터리에 대한
  - 모든 `commit`을 추적하기 위해 `transaction log`를 저장

### Delta Lake의 체크 포인트 파일 생성 주기
- `1/10 commits`

### 다양한 버전의 Delta Table에 어떻게 액세스 하는가
- 3가지 방법
  - `Timestamp 사용 버전 번호`
  - `DESCRIBE HISTORY COMMAND`
  - `UI`를 통해 테이블 변경이력 직접 확인 가능

### Dataframe에서 Delta Table로 data를 upsert하기 위해 어떤 작업을 수행하는가
- Merge operation

### Delta Lake가 `exactly-once`를 보장할 수 있는 이유
- **`transaction log`**를 통해 `Delta Lake`는 `table`에 대해
  - `동시에 실행중인 다른 스트림` 또는
  - `일괄 처리`가 있는 경우에도
  - `exactly-once` 보장 가능

### Delta Lake는 쿼리 성능을 어떻게 최적화 하는가
- `storage`에 저장된 데이터의 **레이아웃 최적화**
- `bin-packing`, `z-ordering`의 두가지 알고리즘 지원
- `bin-packing`
  - 작은 파일을 **큰 파일로 병합**하여
  - 조회 쿼리를 실행할 때 **많은 파일을 스캔하지 않도록 함**
  - 이는 `compaction`을 포함하여 둘째로 **알고리즘 트리거**
  - 이는 `OPTIMIZE` 명령 실행으로
    - `compaction`을 trigger

### VACUUM 테이블 유틸리티 명령의 영향
- `Delta Table`과 연결된 **디렉터리**를
  - **재귀적**으로 진공 상태로 만들고
  - 테이블에 대한 `transaction log`의 최신 상태가 아니며
  - **보존 임계값**보다 오래된 파일 제거